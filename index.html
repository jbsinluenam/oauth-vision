<html>
  <head>
    <style>
  body {
    display: flex;
    align-items: center;
    justify-content: center;
    height: 100vh;
    margin: 0;
    background-color: #333; /* Added a background color for better visibility */
  }

  #results {
    color: white;
    text-align: center;
    margin-top: 20px; /* Adjusted margin for better spacing */
  }

  #results div {
    margin-bottom: 10px; /* Added margin between label and score elements */
  }

  video {
    max-width: 100%; /* Ensure the video doesn't overflow its container */
  }

  h1,
  button {
    display: none; /* Hide the button and h1 element */
  }
</style>

  </head>
  <body>
    <!-- Basic Cloud Vision (Google) Demo -->

    <video autoplay="true" id="videoElement"></video>
    <button id="vision_button">Analyze</button>
    <div id='results'></div>

    <script>
      // Access camera
      var video = document.querySelector("#videoElement");
      if (navigator.mediaDevices.getUserMedia) {
        navigator.mediaDevices.getUserMedia({ video: true })
          .then(function (stream) {
            video.srcObject = stream;
          })
          .catch(function (err) {
            console.log("Something went wrong!");
          });
      }

      // We only get to work when the vision button is clicked
      document.querySelector("#vision_button").addEventListener('click', evt => {
        // extract image as base64, scale it down to reduce data transfer speed
        var scale = 0.25;
        var canvas = document.createElement("canvas");
        canvas.width = video.videoWidth * scale;
        canvas.height = video.videoHeight * scale;
        canvas.getContext('2d')
          .drawImage(video, 0, 0, canvas.width, canvas.height);

        // dataUrl contains base64 version of image
        var dataUrl = canvas.toDataURL();

        // Send image to Google to analyze
        // Documentation of the annotate feature: https://cloud.google.com/vision/docs/reference/rest/v1/images/annotate 
        fetch('https://vision.googleapis.com/v1/images:annotate?key=AIzaSyCZfVcbzxsghvx6RMykG53nrhT705yh-jY', {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json'
          },
          body: JSON.stringify({
            requests: [
              {
                features: [
                  {
                    type: 'LABEL_DETECTION'
                  },
                  {
                    type: 'TEXT_DETECTION'
                  }
                ],
                image: {
                  // have to extract only the image data from dataURL
                  content: dataUrl.substring('data:image/png;base64,'.length)
                }
              }
            ]
          })
        }).then(resp => {
          return resp.json();
        }).then(json => {
          // Simply output the response
          console.log(json);
          results.innerHTML = '';
          json.responses[0].labelAnnotations.forEach(annotation => {
            let description = document.createElement('span');
            let score = document.createElement('span');

            let div = document.createElement('div');
            description.innerText = annotation.description;
            score.innerText = annotation.score;

            div.append(description, score);

            results.append(div);
          });

          // Output detected text
          let textAnnotations = json.responses[0].textAnnotations;
          if (textAnnotations && textAnnotations.length > 1) {
            let textDiv = document.createElement('div');
            textDiv.innerHTML = `<strong>Detected Text:</strong> ${textAnnotations[0].description}`;
            results.append(textDiv);
          }
        });
      });

    </script>
  </body>
</html>
